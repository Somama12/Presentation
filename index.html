<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LISA Global Fit Presentation</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@3.9.1/dist/chart.min.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script defer src="script.js"></script>
    <link rel="stylesheet" href="style.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700;900&family=Orbitron:wght@700&display=stylesheet">
</head>
<body>
    <header id="header" class="glassmorphism fixed top-0 left-0 right-0 z-50">
        <nav class="container mx-auto px-6 py-3 flex justify-between items-center">
            <div class="text-xl font-bold text-white">LISA Global Fit</div>
            <div class="hidden md:flex space-x-8">
                <a href="#hero" class="nav-link active">Home</a>
                <a href="#challenge" class="nav-link">The Challenge</a>
                <a href="#model-comparison" class="nav-link">Model Comparison</a>
                <a href="#kl-comparison" class="nav-link">KL Comparison</a>
                <a href="#future" class="nav-link">Future Work</a>
            </div>
        </nav>
    </header>

    <main>
        <section id="hero" class="relative min-h-screen flex items-center justify-center overflow-hidden bg-gradient-to-br from-[#0f172a] via-[#1e1b4b] to-[#3b0764]">
            <canvas id="gw-ripple-canvas" class="absolute top-0 left-0 w-full h-full z-0"></canvas>
            <div class="absolute top-0 left-0 w-full h-full bg-black bg-opacity-60 z-1"></div>
            <div class="relative z-10 flex flex-col items-center justify-center w-full px-4 py-24 text-center">
                <h1 class="text-4xl sm:text-5xl md:text-6xl lg:text-7xl font-black text-white leading-tight mb-4 drop-shadow-lg">LISA: Listening to the Universeâ€™s Deepest Secrets</h1>
                <p class="text-lg sm:text-xl md:text-2xl text-purple-200 mb-8 max-w-2xl mx-auto">Gravitational Waves, Black Holes, and the Art of the Global Fit</p>
                <button id="scroll-explore" class="btn btn-primary px-8 py-4 rounded-full font-bold text-lg shadow-lg animate-bounce">Scroll to Explore</button>
            </div>
        </section>

        <section id="challenge" class="py-20 md:py-24">
            <div class="container mx-auto px-6">
                <div class="text-content text-center max-w-3xl mx-auto">
                    <h2 class="glow text-4xl lg:text-5xl font-bold text-white mb-4">Unraveling the Cosmic Tapestry</h2>
                    <p class="text-lg text-slate-300">
                        The Laser Interferometer Space Antenna (LISA) will detect gravitational waves from thousands of sources across the universe simultaneously. The data will be a complex superposition of all these signals mixed with instrumental noise. Our challenge is to disentangle this cosmic symphony, identifying each source and its unique parameters. It's like trying to isolate every single voice in a stadium full of people talking at once.
                    </p>
                </div>
                <div class="mt-16 bg-slate-800 p-8 rounded-xl glassmorphism">
                    <h3 class="glow text-3xl lg:text-4xl font-bold text-purple-300 mb-6 text-center">Gravitational Waves: The Cosmic Symphony</h3>
                    <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                        <div>
                            <h4 class="text-xl font-semibold text-white mb-2">What are Gravitational Waves?</h4>
                            <p class="text-slate-300 mb-4">
                                Gravitational waves are ripples in the fabric of spacetime, predicted by Einstein's theory of General Relativity. They are generated by accelerating massive objects, like colliding black holes or neutron stars, carrying energy away from their source and causing spacetime itself to stretch and squeeze as they pass.
                                <br/><br/>
                                <strong>Analogy:</strong> Imagine dropping a stone into a pond; the ripples spread outwards. Gravitational waves are similar, but the pond is spacetime itself.
                            </p>
                            <h4 class="text-xl font-semibold text-white mb-2">Before LISA: Ground-Based Detectors</h4>
                            <p class="text-slate-300">
                                Pioneering observatories like LIGO and Virgo have successfully detected gravitational waves from stellar-mass black hole and neutron star mergers. These ground-based detectors are sensitive to high-frequency gravitational waves (hundreds to thousands of Hz), but are limited by seismic noise and Earth's curvature.
                            </p>
                        </div>
                        <div>
                            <h4 class="text-xl font-semibold text-white mb-2">Why LISA? A Space-Based Observatory</h4>
                            <p class="text-slate-300 mb-4">
                                LISA is designed to detect gravitational waves in the <strong>low-frequency band</strong> (0.1 mHz to 1 Hz), a range inaccessible to ground-based detectors. This unique capability allows us to observe:
                                <ul class="list-disc list-inside text-slate-300 ml-4 mt-2">
                                    <li><strong>Supermassive Black Hole Binaries (SMBHBs):</strong> Mergers at the heart of galaxies.</li>
                                    <li><strong>Extreme Mass Ratio Inspirals (EMRIs):</strong> Compact objects spiraling into supermassive black holes.</li>
                                    <li><strong>Galactic Binaries:</strong> Thousands of binary systems within our own Milky Way.</li>
                                </ul>
                                <strong>Analogy:</strong> If ground-based detectors are like listening to a high-pitched whistle, LISA is designed to hear the deep, resonant hum of the universe.
                            </p>
                        </div>
                    </div>
                </div>
                <div class="mt-16 bg-slate-800 p-8 rounded-xl glassmorphism">
                    <h3 class="glow text-3xl lg:text-4xl font-bold text-purple-300 mb-6 text-center">MCMC: The Cosmic Detective</h3>
                    <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                        <div>
                            <h4 class="text-xl font-semibold text-white mb-2">Parameter Estimation with MCMC</h4>
                            <p class="text-slate-300 mb-4">
                                One of LISA's core data processing steps is to find parameters that match theoretical models to each gravitational wave source. This is known as parameter estimation. In the LISA community, this is usually done with <strong>Reversible Jump Markov Chain Monte Carlo (RJMCMC)</strong>.
                                <br/><br/>
                                RJMCMC is a powerful statistical algorithm that explores the vast parameter space, allowing for changes in the <em>number</em> of sources as well as their individual parameters. This whole process is known as the LISA Global Fit, because every source has to be fit at the same time as every other source.
                            </p>
                            <h4 class="text-xl font-semibold text-white mb-2">The Output: MCMC Chains</h4>
                            <p class="text-slate-300">
                                At the end of the Global Fit, we are left with MCMC chains, which are essentially a long list (an array of points) of all the parameter values considered during the fitting process. More probable parameter values appear more frequently in the chain, effectively mapping out the probability distribution of the source parameters.
                                <br/><br/>
                                <strong>Analogy:</strong> If our cosmic detective notes down every guess they make about a singer's voice in a crowded concert, the MCMC chain is that entire notebook. The more often they guess a certain voice, the more likely that voice is present.
                            </p>
                        </div>
                        <div>
                            <div class="w-full max-w-md mx-auto h-64 md:h-80 glassmorphism rounded-xl p-4 flex items-center justify-center">
                                <canvas id="wave-canvas"></canvas>
                            </div>
                            <h4 class="text-xl font-semibold text-white mt-6 mb-2">Why a Good Model is Crucial</h4>
                            <p class="text-slate-300">
                                We need to generate new samples from these chains that have the same distribution as the old samples. This will let us use the existing fit to each source as an MCMC prior when new data comes in, effectively "re-using" what we've learned so far and speeding up future analyses. A highly accurate model of these complex distributions is therefore essential for robust scientific inference.
                            </p>
                        </div>
                    </div>
                </div>
                <div class="mt-16 bg-slate-800 p-8 rounded-xl glassmorphism">
                    <h3 class="glow text-3xl lg:text-4xl font-bold text-purple-300 mb-6 text-center">Modeling the Cosmic Data: GMM vs. Normalizing Flows</h3>
                    <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                        <div>
                            <h4 class="text-xl font-semibold text-white mb-2">Gaussian Mixture Models (GMMs)</h4>
                            <p class="text-slate-300 mb-4">
                                Gaussian Mixture Models (GMMs) represent data as a combination of multiple Gaussian distributions, each with its own mean, covariance, and weight. They are widely used to model complex probability distributions by approximating them as a mixture of Gaussian "blobs."
                                <br/><br/>
                                <strong>How it Works:</strong> GMMs optimize the parameters of each Gaussian component to maximize the likelihood of the observed data. For LISA, GMMs model the parameter distributions of gravitational wave sources, assuming the data can be approximated by summing weighted Gaussians.
                                <br/><br/>
                                <strong>Limitations:</strong> GMMs struggle with non-Gaussian distributions, such as those with curved, elongated, or multimodal shapes (e.g., Banana distributions), which are common in LISA data. They also require pre-specifying the number of components, which can be difficult for complex datasets.
                            </p>
                            <h4 class="text-xl font-semibold text-white mb-2">Normalizing Flows (NFs)</h4>
                            <p class="text-slate-300 mb-4">
                                Normalizing Flows (NFs) are generative models that transform a simple base distribution (e.g., a standard Gaussian) into a complex target distribution using a series of invertible, differentiable transformations. This makes them highly flexible for modeling LISAâ€™s data.
                                <br/><br/>
                                <strong>How it Works:</strong> NFs learn a sequence of bijective functions that map the data to a base distribution and back. By training on data, NFs can capture intricate, non-Gaussian distributions, such as those with multimodal or non-linear structures.
                                <br/><br/>
                                <strong>Why NFs are Better:</strong> Unlike GMMs, NFs do not assume a specific distribution shape, allowing them to model complex, non-Gaussian data more accurately. They excel at capturing the curved and multimodal distributions typical in gravitational wave data, enabling better sampling and faster convergence in analyses.
                            </p>
                        </div>
                        <div>
                            <div class="w-full max-w-md mx-auto h-64 md:h-80 glassmorphism rounded-xl p-4 flex items-center justify-center">
                                <canvas id="nf-gmm-canvas"></canvas>
                            </div>
                            <h4 class="text-xl font-semibold text-white mt-6 mb-2">Visualizing the Difference</h4>
                            <p class="text-slate-300">
                                The animation below shows a 2D Banana distribution (orange points) being modeled by a GMM (blue contours) and an NF (purple contours). GMMs approximate the data with Gaussian components, often missing curved structures. NFs use flexible transformations to closely follow the dataâ€™s shape, demonstrating superior adaptability.
                                <br/><br/>
                                <button id="toggle-animation" class="btn btn-primary px-6 py-2 rounded-full font-bold text-md">Toggle Animation</button>
                            </p>
                        </div>
                    </div>
                </div>
                <!-- New Section: Understanding KL Divergence -->
                <div class="mt-16 bg-slate-800 p-8 rounded-xl glassmorphism">
                    <h3 class="glow text-3xl lg:text-4xl font-bold text-purple-300 mb-6 text-center">Understanding KL Divergence</h3>
                    <div class="text-content text-slate-300">
                        <p class="mb-4">
                            <strong>Kullback-Leibler (KL) Divergence</strong> measures how much one probability distribution differs from another. It quantifies how well a modelâ€™s distribution (e.g., GMM or NF) matches a target distribution.
                        </p>
                        <p class="mb-4">
                            <strong>Formula:</strong>
                            <div class="math-block">
                                \[ D_{\text{KL}}(P || Q) = \int P(x) \log \left( \frac{P(x)}{Q(x)} \right) dx \]
                            </div>
                            Here, \( P(x) \) is the true distribution, and \( Q(x) \) is the modelâ€™s distribution. For discrete data:
                            <div class="math-block">
                                \[ D_{\text{KL}}(P || Q) = \sum_i P(x_i) \log \left( \frac{P(x_i)}{Q(x_i)} \right) \]
                            </div>
                        </p>
                        <p class="mb-4">
                            <strong>What It Compares:</strong> In our tests, KL Divergence compares the true data distribution (e.g., 2Dâ€“5D Gaussian or Banana datasets) to distributions modeled by GMMs or NFs. Lower scores mean a better match.
                        </p>
                        <p class="mb-4">
                            <strong>Score Interpretation:</strong>
                            <ul class="list-disc list-inside ml-4">
                                <li><strong>Low (< 0.1):</strong> Excellent fit (e.g., GMM on 5D Gaussian: 0.0067).</li>
                                <li><strong>Moderate (0.1â€“0.5):</strong> Decent fit, some mismatches (e.g., NF on 5D Banana: 0.0393).</li>
                                <li><strong>High (> 0.5):</strong> Poor fit, significant differences (e.g., GMM on 2D Banana: 1.4573).</li>
                            </ul>
                            NFs often achieve lower scores on non-Gaussian data (e.g., 0.0393 vs. GMMâ€™s 0.3928 on 5D Banana), showing better flexibility.
                        </p>
                    </div>
                </div>
            </div>
        </section>

        <section id="model-comparison" class="py-20 md:py-24">
            <div class="container mx-auto px-6 max-w-4xl">
                <div class="text-content text-center">
                    <h2 class="glow text-4xl lg:text-5xl font-bold text-white mb-4">Model Comparison Across Dimensions</h2>
                    <p class="text-lg text-slate-300 mb-12">
                        Explore the performance of Gaussian Mixture Models (GMMs) and Normalizing Flows (NFs) on 2D to 5D datasets. Click each graph to view detailed results for Gaussian and Non-Gaussian (Banana) distributions.
                    </p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8 text-center">
                    <div class="glassmorphism p-8 min-h-[420px] rounded-2xl flex flex-col items-center">
                        <img onclick="openModal(this.src)" src="2d.png" alt="GMM and NF fit on 2D dataset" class="cursor-pointer mb-4 w-32 h-32 object-contain rounded-xl shadow-lg transition-transform duration-200 hover:scale-105">
                        <p class="text-base text-slate-500 mb-2">2D Results</p>
                        <h3 class="text-2xl font-bold text-purple-300 mb-3">2D Data</h3>
                        <p class="text-slate-400 text-md">
                            GMM on 2D data shows strong performance on Gaussian data (KL: 0.0204) but struggles with Banana data (KL: 1.4573). NF performs moderately on Gaussian (KL: 0.3726) and better on Banana (KL: 1.1247), indicating improved adaptability to non-Gaussian structures.
                        </p>
                    </div>
                    <div class="glassmorphism p-8 min-h-[420px] rounded-2xl flex flex-col items-center">
                        <img onclick="openModal(this.src)" src="3d.png" alt="GMM and NF fit on 3D dataset" class="cursor-pointer mb-4 w-32 h-32 object-contain rounded-xl shadow-lg transition-transform duration-200 hover:scale-105">
                        <p class="text-base text-slate-500 mb-2">3D Results</p>
                        <h3 class="text-2xl font-bold text-purple-300 mb-3">3D Data</h3>
                        <p class="text-slate-400 text-md">
                            GMM on 3D data excels on Gaussian data (KL: 0.0000) but has moderate performance on Banana data (KL: 0.6176). NF struggles with Gaussian (KL: 0.7346) but outperforms GMM on Banana (KL: 0.5438), showing robustness for non-Gaussian data.
                        </p>
                    </div>
                    <div class="glassmorphism p-8 min-h-[420px] rounded-2xl flex flex-col items-center">
                        <img onclick="openModal(this.src)" src="4d.png" alt="GMM and NF fit on 4D dataset" class="cursor-pointer mb-4 w-32 h-32 object-contain rounded-xl shadow-lg transition-transform duration-200 hover:scale-105">
                        <p class="text-base text-slate-500 mb-2">4D Results</p>
                        <h3 class="text-2xl font-bold text-purple-300 mb-3">4D Data</h3>
                        <p class="text-slate-400 text-md">
                            GMM on 4D data shows excellent fit for Gaussian data (KL: 0.0000) but weaker performance on Banana data (KL: 0.4025). NF underperforms on Gaussian (KL: 0.5977) but excels on Banana (KL: 0.2612), highlighting its strength in non-Gaussian distributions.
                        </p>
                    </div>
                    <div class="glassmorphism p-8 min-h-[420px] rounded-2xl flex flex-col items-center">
                        <img onclick="openModal(this.src)" src="5d.png" alt="GMM and NF fit on 5D dataset" class="cursor-pointer mb-4 w-32 h-32 object-contain rounded-xl shadow-lg transition-transform duration-200 hover:scale-105">
                        <p class="text-base text-slate-500 mb-2">5D Results</p>
                        <h3 class="text-2xl font-bold text-purple-300 mb-3">5D Data</h3>
                        <p class="text-slate-400 text-md">
                            GMM on 5D data achieves near-perfect fit for Gaussian data (KL: 0.0067) but struggles on Banana data (KL: 0.3928). NF shows moderate performance on Gaussian (KL: 0.3326) and excels on Banana (KL: 0.0393), demonstrating superior flexibility.
                        </p>
                    </div>
                </div>
                <div id="imgModal" onclick="closeModal()" class="fixed inset-0 bg-black bg-opacity-80 hidden justify-center items-center z-50">
                    <span onclick="closeModal()" class="absolute top-5 right-5 text-white text-3xl cursor-pointer">&times;</span>
                    <img id="modalImg" onclick="event.stopPropagation()" class="max-w-full max-h-full rounded-lg shadow-xl">
                </div>
                <script>
                    function openModal(src) {
                        document.getElementById('imgModal').style.display = 'flex';
                        document.getElementById('modalImg').src = src;
                    }
                    function closeModal() {
                        document.getElementById('imgModal').style.display = 'none';
                    }
                </script>
            </div>
        </section>

        <section id="kl-comparison" class="py-20 md:py-24">
            <div class="container mx-auto px-6 max-w-4xl">
                <div class="text-content text-center">
                    <h2 class="glow text-4xl lg:text-5xl font-bold text-white mb-4">KL Divergence Comparison</h2>
                    <p class="text-lg text-slate-300 mb-12">
                        Compare the KL divergence scores for GMM and Normalizing Flows across 2D to 5D datasets for Gaussian and Non-Gaussian (Banana) distributions, highlighting model performance trends.
                    </p>
                </div>
                <div class="chart-container glassmorphism rounded-xl p-4">
                    <canvas id="kl-chart"></canvas>
                </div>
            </div>
        </section>

        <section id="comparison" class="py-20 md:py-24">
            <div class="container mx-auto px-6 max-w-4xl">
                <div class="text-content text-center">
                    <h2 class="glow text-4xl lg:text-5xl font-bold text-white mb-4">Log-Likelihood Comparison Across Different Datasets</h2>
                    <p class="text-lg text-slate-300 mb-12"></p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-3 gap-8 text-center">
                    <div class="glassmorphism p-8 min-h-[420px] rounded-2xl flex flex-col items-center">
                        <img onclick="openModal(this.src)" src="gaussian_projection.jpg" alt="Optimize Flow" class="cursor-pointer mb-4 w-32 h-32 object-contain rounded-xl shadow-lg transition-transform duration-200 hover:scale-105">
                        <p class="text-base text-slate-500 mb-2"></p>
                        <h3 class="text-2xl font-bold text-purple-300 mb-3">Actual Fit</h3>
                        <p class="text-slate-400 text-md">The actual graph of how the data looks like.</p>
                    </div>
                    <div class="glassmorphism p-8 min-h-[420px] rounded-2xl flex flex-col items-center">
                        <img onclick="openModal(this.src)" src="perfect_fit.jpg" alt="Collaborate" class="cursor-pointer mb-4 w-32 h-32 object-contain rounded-xl shadow-lg transition-transform duration-200 hover:scale-105">
                        <p class="text-base text-slate-500 mb-2"></p>
                        <h3 class="text-2xl font-bold text-purple-300 mb-3">Standard fit</h3>
                        <p class="text-slate-400 text-md">The graph confirms the Gaussian dataset aligns with N(0,1) (statistic 0.3475 < critical value 0.7840), while Gaussian Mixture (20.1182), Uniform (12.0752), and Exponential (49.7306) are non-Gaussian. This highlights the need for flexible models like Normalizing Flows for LISAâ€™s complex data distributions.</p>
                    </div>
                    <div class="glassmorphism p-8 min-h-[420px] rounded-2xl flex flex-col items-center">
                        <img onclick="openModal(this.src)" src="GMM_fit.jpg" alt="Test on Data" class="cursor-pointer mb-4 w-32 h-32 object-contain rounded-xl shadow-lg transition-transform duration-200 hover:scale-105">
                        <p class="text-base text-slate-500 mb-2"></p>
                        <h3 class="text-2xl font-bold text-purple-300 mb-3">Gaussian Mixture Model Fit</h3>
                        <p class="text-slate-400 text-md">The graph shows GMM fits with 1 component for Gaussian data (log-likelihood ~2.20) and 2â€“3 components for Gaussian Mixture (1.90), Uniform (1.10), and Exponential (1.30). GMMs capture Gaussian-like structures but struggle with non-Gaussian data, highlighting limitations for LISAâ€™s complex signals.</p>
                    </div>
                    <div class="glassmorphism p-8 min-h-[420px] rounded-2xl flex flex-col items-center">
                        <img onclick="openModal(this.src)" src="gmm_vs_nf.jpg" alt="Card 4" class="cursor-pointer mb-4 w-32 h-32 object-contain rounded-xl shadow-lg transition-transform duration-200 hover:scale-105">
                        <p class="text-base text-slate-500 mb-2">GMM vs NF</p>
                        <h3 class="text-2xl font-bold text-purple-300 mb-3">Gaussian Mixture Models vs NFs 1D data</h3>
                        <p class="text-slate-400 text-md">The graph shows NFs not outperforming GMMs on 1D non-Gaussian data (e.g., Gaussian Mixture - Flow LL (mean Â± std): -1.4242 Â± 0.0449, GMM LL: -1.2886, Flow Advantage: -0.1356) after optimized training.</p>
                    </div>
                    <div class="glassmorphism p-8 min-h-[420px] rounded-2xl flex flex-col items-center">
                        <img onclick="openModal(this.src)" src="nf_vs_gmm_2d.png" alt="Card 5" class="cursor-pointer mb-4 w-32 h-32 object-contain rounded-xl shadow-lg transition-transform duration-200 hover:scale-105">
                        <p class="text-base text-slate-500 mb-2">NF vs GMM 2D</p>
                        <h3 class="text-2xl font-bold text-purple-300 mb-3">NFs vs GMMs 2D Data</h3>
                        <p class="text-slate-400 text-md">The graph shows NFs still not outperforming GMMs for 2D non-Gaussian data ( Gaussian Mixture - Flow LL: -2.5813 Â± 0.1604, GMM LL: -2.3733, Flow Advantage: -0.2080, GMM Components: 2), with smoother contours.</p>
                    </div>
                    <div class="glassmorphism p-8 min-h-[420px] rounded-2xl flex flex-col items-center">
                        <img onclick="openModal(this.src)" src="nf_vs_gmm_3d.png" alt="Card 6" class="cursor-pointer mb-4 w-32 h-32 object-contain rounded-xl shadow-lg transition-transform duration-200 hover:scale-105">
                        <p class="text-base text-slate-500 mb-2">NF vs GMM 3D</p>
                        <h3 class="text-2xl font-bold text-purple-300 mb-3">NFs vs GMMs 3D Data</h3>
                        <p class="text-slate-400 text-md">The graph shows NFs still not outperforming GMMs in 3D for non-Gaussian data (Gaussian Mixture - Flow LL: -8.1994 Â± 4.7496, GMM LL: -3.3478, Flow Advantage: -4.8516, GMM Components:2 ), with smoother contours.</p>
                    </div>
                </div>
                <div id="imgModal" onclick="closeModal()" class="fixed inset-0 bg-black bg-opacity-80 hidden justify-center items-center z-50">
                    <span onclick="closeModal()" class="absolute top-5 right-5 text-white text-3xl cursor-pointer">&times;</span>
                    <img id="modalImg" onclick="event.stopPropagation()" class="max-w-full max-h-full rounded-lg shadow-xl">
                </div>
                <script>
                    function openModal(src) {
                        document.getElementById('imgModal').style.display = 'flex';
                        document.getElementById('modalImg').src = src;
                    }
                    function closeModal() {
                        document.getElementById('imgModal').style.display = 'none';
                    }
                </script>
            </div>
        </section>

        <section id="future" class="py-20 md:py-24">
            <div class="container mx-auto px-6 max-w-4xl">
                <div class="text-content text-center">
                    <h2 class="glow text-4xl lg:text-5xl font-bold text-white mb-4">Future Work & Collaboration</h2>
                    <p class="text-lg text-slate-300 mb-12">
                        The journey is just beginning. Our next steps involve refining the model and applying it to more realistic data to unlock new frontiers in gravitational wave astronomy.
                    </p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-3 gap-8 text-center">
                    <div class="glassmorphism p-6 rounded-lg">
                        <h3 class="text-xl font-bold text-purple-300 mb-3">Optimize the Flow</h3>
                        <p class="text-slate-400">Refine the Normalizing Flow architecture, tune hyperparameters, and experiment with different transforms to improve performance on complex, non-Gaussian data.</p>
                    </div>
                    <div class="glassmorphism p-6 rounded-lg">
                        <h3 class="text-xl font-bold text-purple-300 mb-3">Test on Realistic Data</h3>
                        <p class="text-slate-400">Apply the optimized model to actual MCMC chains from full LISA Global Fit simulations and rigorously compare its performance against GMMs.</p>
                    </div>
                    <div class="glassmorphism p-6 rounded-lg">
                        <h3 class="text-xl font-bold text-purple-300 mb-3">Contribute & Collaborate</h3>
                        <p class="text-slate-400">Integrate the successful model into core LISA data analysis pipelines (like GLASS or Erebor) in collaboration with NASA Marshall and other partners.</p>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <footer class="bg-slate-900 border-t border-slate-800 py-8">
        <div class="container mx-auto px-6 text-center text-slate-500">
            <p>Research and interactive report by Somama Siddiqui and Suyog Gaire.<br>Mentors: Robbie Rosati, Maria Jose Bustamante, Alexander Criswell, Andrea Derdzinski, Manuel Pichardo Marcano, Mathew Digman, Ilija Medan.</p>
        </div>
    </footer>

    <div id="code-modal" class="modal">
        <div class="modal-content">
            <button id="modal-close-btn" class="modal-close-btn">Ã—</button>
            <h3 id="modal-title" class="text-2xl font-bold text-purple-300 mb-4"></h3>
            <pre class="code-block"><code id="code-display"></code></pre>
        </div>
    </div>
</body>
</html>